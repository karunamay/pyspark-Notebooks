{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe2fa891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kpathak/opt/anaconda3/envs/mamlTesting/lib/python3.8/site-packages/pyspark'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initializing pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ee9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://naomi-fridman.medium.com/install-pyspark-to-run-on-jupyter-notebook-on-windows-4ec2009de21f\n",
    "#https://github.com/spark-examples/pyspark-examples/\n",
    "#https://www.datacamp.com/tutorial/pyspark-tutorial-getting-started-with-pyspark\n",
    "#https://www.guru99.com/pyspark-tutorial.html\n",
    "#https://sparkbyexamples.com/pyspark/install-pyspark-in-anaconda-jupyter-notebook/\n",
    "#follow conda install for pyspark and findaprk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9beaa37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/kpathak/opt/anaconda3/envs/mamlTesting/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/10/25 19:01:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/25 19:01:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fe5ea535f70>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sc =  SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate()\n",
    "spark= sc\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed68e589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.101:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkByExamples.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe5ea535f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "be709763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3cf6df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age\n",
      "0   Scott   50\n",
      "1    Jeff   45\n",
      "2  Thomas   54\n",
      "3     Ann   34\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n",
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "| Scott| 50|\n",
      "|  Jeff| 45|\n",
      "|Thomas| 54|\n",
      "|   Ann| 34|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create spark data frame\n",
    "import pandas as pd    \n",
    "data = [['Scott', 50], ['Jeff', 45], ['Thomas', 54],['Ann',34]] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "pandasDF = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
    "  \n",
    "# print dataframe. \n",
    "print(pandasDF)\n",
    "sparkDF=spark.createDataFrame(pandasDF) \n",
    "sparkDF.printSchema()\n",
    "sparkDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "77943795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paralleziation\n",
    "nums= spark.sparkContext.parallelize([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "66acaf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "50c51ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "4 \n",
      "9 \n",
      "16 \n",
      "CPU times: user 4.17 ms, sys: 3.82 ms, total: 7.99 ms\n",
      "Wall time: 75.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "squared = nums.map(lambda x: x*x).collect()\n",
    "for num in squared:\n",
    "    print('%i ' % (num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "83da522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "4 \n",
      "9 \n",
      "16 \n",
      "CPU times: user 402 µs, sys: 290 µs, total: 692 µs\n",
      "Wall time: 473 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num1=[1,2,3,4]\n",
    "for i in num1:\n",
    "    print('%i '% (i*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b67617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQLContext allows connecting the engine with different data sources. It is used to initiate the functionalities of Spark SQL.\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd4b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tuple\n",
    "tuple=[('John',19),('Smith',29),('Adam',35),('Henry',50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8973e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating rdd\n",
    "rdd = spark.sparkContext.parallelize(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8160c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='John', age=19),\n",
       " Row(name='Smith', age=29),\n",
       " Row(name='Adam', age=35),\n",
       " Row(name='Henry', age=50)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting tuples\n",
    "rdd.map(lambda x: Row(name=x[0], age=int(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca30ae7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| John| 19|\n",
      "|Smith| 29|\n",
      "| Adam| 35|\n",
      "|Henry| 50|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create dataframe\n",
    "ppl = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "DF_ppl = sqlContext.createDataFrame(ppl)\n",
    "DF_ppl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e925c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print schema\n",
    "DF_ppl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147706b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/25 19:03:30 WARN SparkContext: The path https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv has been added already. Overwriting of added paths is not supported in the current version.\n"
     ]
    }
   ],
   "source": [
    "#Machine learning example\n",
    "url = \"https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "from pyspark import SparkFiles\n",
    "sqlContext = SQLContext(sparkContext=spark.sparkContext, sparkSession=spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2ccaf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data fetchung from uri\n",
    "df = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ab5810a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55b58e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4bb9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|x  |age|workclass|fnlwgt|education   |educational-num|marital-status    |occupation       |relationship|race |gender|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|1  |25 |Private  |226802|11th        |7              |Never-married     |Machine-op-inspct|Own-child   |Black|Male  |0           |0           |40            |United-States |<=50K |\n",
      "|2  |38 |Private  |89814 |HS-grad     |9              |Married-civ-spouse|Farming-fishing  |Husband     |White|Male  |0           |0           |50            |United-States |<=50K |\n",
      "|3  |28 |Local-gov|336951|Assoc-acdm  |12             |Married-civ-spouse|Protective-serv  |Husband     |White|Male  |0           |0           |40            |United-States |>50K  |\n",
      "|4  |44 |Private  |160323|Some-college|10             |Married-civ-spouse|Machine-op-inspct|Husband     |Black|Male  |7688        |0           |40            |United-States |>50K  |\n",
      "|5  |18 |?        |103497|Some-college|10             |Never-married     |?                |Own-child   |White|Female|0           |0           |30            |United-States |<=50K |\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b977a03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: string (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: string (nullable = true)\n",
      " |-- capital-loss: string (nullable = true)\n",
      " |-- hours-per-week: string (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema= False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "214c88d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: float (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: float (nullable = true)\n",
      " |-- capital-loss: float (nullable = true)\n",
      " |-- hours-per-week: float (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import all from `sql.types`\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "# List of continuous features\n",
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital-gain', 'educational-num', 'capital-loss', 'hours-per-week']\n",
    "# Convert the type\n",
    "df_string = convertColumn(df, CONTI_FEATURES, FloatType())\n",
    "df_string.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5811c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|fnlwgt|\n",
      "+---+------+\n",
      "| 25|226802|\n",
      "| 38| 89814|\n",
      "| 28|336951|\n",
      "| 44|160323|\n",
      "| 18|103497|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select column\n",
    "df.select(df.age,df.fnlwgt).show(5)\n",
    "# df.select(df[\"age\"],df[\"fnlwgt\"]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8f4e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:==========================================>            (78 + 1) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   education|count|\n",
      "+------------+-----+\n",
      "|        10th| 1389|\n",
      "|     Masters| 2657|\n",
      "|     5th-6th|  509|\n",
      "|  Assoc-acdm| 1601|\n",
      "|   Assoc-voc| 2061|\n",
      "|     7th-8th|  955|\n",
      "|         9th|  756|\n",
      "|     HS-grad|15784|\n",
      "|   Bachelors| 8025|\n",
      "|        11th| 1812|\n",
      "|     1st-4th|  247|\n",
      "|   Preschool|   83|\n",
      "|        12th|  657|\n",
      "|   Doctorate|  594|\n",
      "|Some-college|10878|\n",
      "| Prof-school|  834|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupby\n",
    "df2=df.groupBy(df['education']).count()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "eca9ddab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   education|count|\n",
      "+------------+-----+\n",
      "|     HS-grad|15784|\n",
      "|Some-college|10878|\n",
      "|   Bachelors| 8025|\n",
      "|     Masters| 2657|\n",
      "|   Assoc-voc| 2061|\n",
      "|        11th| 1812|\n",
      "|  Assoc-acdm| 1601|\n",
      "|        10th| 1389|\n",
      "|     7th-8th|  955|\n",
      "| Prof-school|  834|\n",
      "|         9th|  756|\n",
      "|        12th|  657|\n",
      "|   Doctorate|  594|\n",
      "|     5th-6th|  509|\n",
      "|     1st-4th|  247|\n",
      "|   Preschool|   83|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1=df.groupBy(df['education']).count()\n",
    "df1=df1.sort(df1['count'],ascending=False)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "fd673514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 78:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+------------------+------------------+--------------+------+\n",
      "|summary|                 x|               age|  workclass|            fnlwgt|   education|   educational-num|marital-status|      occupation|relationship|              race|gender|      capital-gain|      capital-loss|    hours-per-week|native-country|income|\n",
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+------------------+------------------+--------------+------+\n",
      "|  count|             48842|             48842|      48842|             48842|       48842|             48842|         48842|           48842|       48842|             48842| 48842|             48842|             48842|             48842|         48842| 48842|\n",
      "|   mean|           24421.5| 38.64358543876172|       null|189664.13459727284|        null|10.078088530363212|          null|            null|        null|              null|  null|1079.0676262233324| 87.50231358257237|40.422382375824085|          null|  null|\n",
      "| stddev|14099.615260708357|13.710509934443472|       null| 105604.0254231574|        null| 2.570972755592249|          null|            null|        null|              null|  null| 7452.019057655406|403.00455212435935|12.391444024252278|          null|  null|\n",
      "|    min|                 1|                17|          ?|             12285|        10th|                 1|      Divorced|               ?|     Husband|Amer-Indian-Eskimo|Female|                 0|                 0|                 1|             ?| <=50K|\n",
      "|    max|             48842|                90|Without-pay|           1490400|Some-college|                16|       Widowed|Transport-moving|        Wife|             White|  Male|             99999|              4356|                99|    Yugoslavia|  >50K|\n",
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------+------------------+------------------+------------------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#describe data\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e59fa169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      capital-gain|\n",
      "+-------+------------------+\n",
      "|  count|             48842|\n",
      "|   mean|1079.0676262233324|\n",
      "| stddev| 7452.019057655406|\n",
      "|    min|                 0|\n",
      "|    max|             99999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#describe a particular column\n",
    "df.describe('capital-gain').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a85ebb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+-----------+---------+------------+-------+------------+----------------+---------+-----------+\n",
      "|age_workclass|  ?|Federal-gov|Local-gov|Never-worked|Private|Self-emp-inc|Self-emp-not-inc|State-gov|Without-pay|\n",
      "+-------------+---+-----------+---------+------------+-------+------------+----------------+---------+-----------+\n",
      "|           69| 32|          2|        9|           0|     66|           7|              26|        7|          0|\n",
      "|           88|  0|          0|        0|           0|      2|           0|               4|        0|          0|\n",
      "|           56| 17|         23|       38|           0|    351|          30|              81|       24|          0|\n",
      "|           42| 22|         46|       98|           0|    755|          52|             128|       64|          0|\n",
      "|           24| 56|         21|       56|           0|    986|          10|              35|       42|          0|\n",
      "|           37| 18|         51|       91|           0|    899|          47|             115|       59|          0|\n",
      "|           25| 46|         14|       64|           0|    980|          15|              36|       40|          0|\n",
      "|           52| 24|         41|       65|           0|    475|          36|              68|       28|          1|\n",
      "|           20|184|         13|       20|           2|    834|          11|              16|       33|          0|\n",
      "|           46| 16|         51|      111|           0|    720|          52|              89|       57|          1|\n",
      "|           57| 26|         26|       40|           0|    316|          41|              77|       25|          0|\n",
      "|           78| 13|          0|        2|           0|      9|           4|               6|        0|          0|\n",
      "|           29| 48|         34|       71|           0|    942|          18|              66|       43|          1|\n",
      "|           84|  4|          0|        2|           0|      5|           1|               1|        0|          0|\n",
      "|           61| 48|         15|       31|           0|    264|          21|              55|       16|          0|\n",
      "|           89|  1|          0|        0|           0|      1|           0|               0|        0|          0|\n",
      "|           74| 17|          2|        2|           0|     31|           5|              15|        4|          1|\n",
      "|           60| 43|         18|       28|           0|    255|          21|              64|       20|          0|\n",
      "|           85|  0|          0|        0|           0|      3|           1|               1|        0|          0|\n",
      "|           28| 55|         23|       74|           0|    990|          21|              72|       45|          0|\n",
      "+-------------+---+-----------+---------+------------+-------+------------+----------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating a cross tab\n",
    "df1=df.crosstab('age', 'workclass')\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "84450a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " 'age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'educational-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'income']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns\n",
    "df.drop('education_num').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9dbde9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20211"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter data \n",
    "df.filter(df.age > 40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3b4c3dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg(capital-gain)|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 581.8424836601307|\n",
      "|       Never-married|  384.382639449029|\n",
      "|Married-spouse-ab...| 629.0047770700637|\n",
      "|            Divorced| 793.6755615860094|\n",
      "|             Widowed| 603.6442687747035|\n",
      "|   Married-AF-spouse|2971.6216216216217|\n",
      "|  Married-civ-spouse|1739.7006121810625|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grouby statistics\n",
    "df.groupby(df['marital-status']).agg({'capital-gain' : 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2832a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9c775283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+\n",
      "|  x|age|workclass|fnlwgt|   education|educational-num|    marital-status|       occupation|relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|age_square|\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+\n",
      "|  1| 25|  Private|226802|        11th|              7|     Never-married|Machine-op-inspct|   Own-child|Black|  Male|           0|           0|            40| United-States| <=50K|       625|\n",
      "|  2| 38|  Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|     Husband|White|  Male|           0|           0|            50| United-States| <=50K|      1444|\n",
      "|  3| 28|Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|     Husband|White|  Male|           0|           0|            40| United-States|  >50K|       784|\n",
      "|  4| 44|  Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|     Husband|Black|  Male|        7688|           0|            40| United-States|  >50K|      1936|\n",
      "|  5| 18|        ?|103497|Some-college|             10|     Never-married|                ?|   Own-child|White|Female|           0|           0|            30| United-States| <=50K|       324|\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# 1 Select the column\n",
    "age_square = df.select(df[\"age\"]*df[\"age\"])\n",
    "\n",
    "# 2 Apply the transformation and add it to the DataFrame\n",
    "df = df.withColumn(\"age_square\", df[\"age\"]*df[\"age\"])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "70cc6907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+\n",
      "|age|age_square|workclass|fnlwgt|   education|educational-num|    marital-status|       occupation|relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|\n",
      "+---+----------+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+\n",
      "| 25|       625|  Private|226802|        11th|              7|     Never-married|Machine-op-inspct|   Own-child|Black|  Male|           0|           0|            40| United-States|\n",
      "| 38|      1444|  Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|     Husband|White|  Male|           0|           0|            50| United-States|\n",
      "| 28|       784|Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|     Husband|White|  Male|           0|           0|            40| United-States|\n",
      "| 44|      1936|  Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|     Husband|Black|  Male|        7688|           0|            40| United-States|\n",
      "| 18|       324|        ?|103497|Some-college|             10|     Never-married|                ?|   Own-child|White|Female|           0|           0|            30| United-States|\n",
      "+---+----------+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select columns\n",
    "df1 = df.select(df['age'], df['age_square'], df['workclass'], df['fnlwgt'], df['education'], df['educational-num'], df['marital-status'],\n",
    "           df['occupation'], df['relationship'], df['race'], df['gender'], df['capital-gain'], df['capital-loss'],df['hours-per-week'], df['native-country'])\n",
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "875f9715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48842"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a7e0a569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "+--------------+---------------------+\n",
      "|native-country|count(native-country)|\n",
      "+--------------+---------------------+\n",
      "|   Philippines|                  295|\n",
      "|       Germany|                  206|\n",
      "|      Cambodia|                   28|\n",
      "|        France|                   38|\n",
      "|        Greece|                   49|\n",
      "+--------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter\n",
    "print(df.filter(df['native-country'] == 'Holand-Netherlands').count())\n",
    "df.groupby(df['native-country']).agg({'native-country': 'count'}).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bd2d43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48841"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing something\n",
    "df_remove = df.filter(df['native-country'] != 'Holand-Netherlands')\n",
    "df_remove.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ab02912f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(workclass='Self-emp-not-inc', count=3862),\n",
       " Row(workclass='Local-gov', count=3136),\n",
       " Row(workclass='State-gov', count=1981),\n",
       " Row(workclass='Private', count=33906),\n",
       " Row(workclass='Without-pay', count=21),\n",
       " Row(workclass='Federal-gov', count=1432),\n",
       " Row(workclass='Never-worked', count=10),\n",
       " Row(workclass='?', count=2799),\n",
       " Row(workclass='Self-emp-inc', count=1695)]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at group states for workclass\n",
    "df.groupBy(df['workclass']).count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ef68fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+-----------------+-------------+\n",
      "|  x|age|workclass|fnlwgt|   education|educational-num|    marital-status|       occupation|relationship| race|gender|capital-gain|capital-loss|hours-per-week|native-country|income|workclass_encoded|workclass_vec|\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+-----------------+-------------+\n",
      "|  1| 25|  Private|226802|        11th|              7|     Never-married|Machine-op-inspct|   Own-child|Black|  Male|           0|           0|            40| United-States| <=50K|              0.0|(9,[0],[1.0])|\n",
      "|  2| 38|  Private| 89814|     HS-grad|              9|Married-civ-spouse|  Farming-fishing|     Husband|White|  Male|           0|           0|            50| United-States| <=50K|              0.0|(9,[0],[1.0])|\n",
      "|  3| 28|Local-gov|336951|  Assoc-acdm|             12|Married-civ-spouse|  Protective-serv|     Husband|White|  Male|           0|           0|            40| United-States|  >50K|              2.0|(9,[2],[1.0])|\n",
      "|  4| 44|  Private|160323|Some-college|             10|Married-civ-spouse|Machine-op-inspct|     Husband|Black|  Male|        7688|           0|            40| United-States|  >50K|              0.0|(9,[0],[1.0])|\n",
      "|  5| 18|        ?|103497|Some-college|             10|     Never-married|                ?|   Own-child|White|Female|           0|           0|            30| United-States| <=50K|              3.0|(9,[3],[1.0])|\n",
      "+---+---+---------+------+------------+---------------+------------------+-----------------+------------+-----+------+------------+------------+--------------+--------------+------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#building data processing pipeline\n",
    "### Example encoder\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "string_Indexer = StringIndexer(inputCol=\"workclass\", outputCol=\"workclass_encoded\")\n",
    "model = string_Indexer.fit(df)\n",
    "indexed = model.transform(df)\n",
    "encoder = OneHotEncoder(dropLast=False, inputCol=\"workclass_encoded\", outputCol=\"workclass_vec\").fit(indexed)\n",
    "encoded = encoder.transform(indexed)\n",
    "encoded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f806f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+\n",
      "|workclass_encoded|workclass_vec|\n",
      "+-----------------+-------------+\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              2.0|(9,[2],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              3.0|(9,[3],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              3.0|(9,[3],[1.0])|\n",
      "|              1.0|(9,[1],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              6.0|(9,[6],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              3.0|(9,[3],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              4.0|(9,[4],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "|              0.0|(9,[0],[1.0])|\n",
      "+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded.select('workclass_encoded','workclass_vec').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9d48942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data-testing\n",
    "#create the structure of schema\n",
    "# schema = StructType().add(\"id\",\"integer\").add(\"name\",\"string\").add(\"qualification\",\"string\").add(\"age\", \"integer\").add(\"gender\", \"string\")\n",
    "# data = [\n",
    "#     (1,'John',\"B.A.\", 20, \"Male\"),\n",
    "#     (2,'Martha',\"B.Com.\", 20, \"Female\"),\n",
    "#     (3,'Mona',\"B.Com.\", 21, \"Female\"),\n",
    "#     (4,'Harish',\"B.Sc.\", 22, \"Male\"),\n",
    "#     (5,'Jonny',\"B.A.\", 22, \"Male\"),\n",
    "#     (6,'Maria',\"B.A.\", 23, \"Female\"),\n",
    "#     (7,'Monalisa',\"B.A.\", 21, \"Female\")\n",
    "# ]\n",
    "# df_test = spark.createDataFrame(data, schema=schema)\n",
    "# qualification_indexer = StringIndexer(inputCol=\"qualification\", outputCol=\"qualificationIndex\")\n",
    "# #Fits a model to the input dataset with optional parameters.\n",
    "# df1_test = qualification_indexer.fit(df_test).transform(df_test)\n",
    "# df1_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "deb1ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoder to qualificationIndex\n",
    "# onehotencoder_qualification_vector = OneHotEncoder(inputCol=\"qualificationIndex\", outputCol=\"qualification_vec\")\n",
    "# df11_test = onehotencoder_qualification_vector.fit(df1_test).transform(df1_test)\n",
    "# df11_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ed0ec4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "CATE_FEATURES = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country','income']\n",
    "# CATE_FEATURES = ['workclass', 'education']\n",
    "\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in CATE_FEATURES:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()],\n",
    "                                     outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx =  StringIndexer(inputCol=\"income\", outputCol=\"newlabel\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "18b76fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_d13bc29328d3,\n",
       " OneHotEncoder_5d817771b9e2,\n",
       " StringIndexer_834dbdee2656,\n",
       " OneHotEncoder_2c99eff7c4a2,\n",
       " StringIndexer_722880280649,\n",
       " OneHotEncoder_7fe1de319cae,\n",
       " StringIndexer_ffb3651de9b1,\n",
       " OneHotEncoder_5f88ad0f1f8e,\n",
       " StringIndexer_424efa9aacbb,\n",
       " OneHotEncoder_a65bde17d2de,\n",
       " StringIndexer_a95c9282cb16,\n",
       " OneHotEncoder_3eac99a70a3b,\n",
       " StringIndexer_4ea144e46c03,\n",
       " OneHotEncoder_510482c280f6,\n",
       " StringIndexer_8b346fd910c8,\n",
       " OneHotEncoder_4cd872fdede8,\n",
       " StringIndexer_6a30065ccbc9,\n",
       " OneHotEncoder_fc14e6f6b8f8,\n",
       " StringIndexer_d28b980e817e]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8dcfdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclassclassVec',\n",
       " 'educationclassVec',\n",
       " 'marital-statusclassVec',\n",
       " 'occupationclassVec',\n",
       " 'relationshipclassVec',\n",
       " 'raceclassVec',\n",
       " 'genderclassVec',\n",
       " 'native-countryclassVec',\n",
       " 'incomeclassVec',\n",
       " 'age',\n",
       " 'fnlwgt',\n",
       " 'capital-gain',\n",
       " 'educational-num',\n",
       " 'capital-loss',\n",
       " 'hours-per-week']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assembling all features\n",
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital-gain', 'educational-num', 'capital-loss', 'hours-per-week']\n",
    "# CONTI_FEATURES  = ['age', 'fnlwgt']\n",
    "\n",
    "assemblerInputs = [c + \"classVec\" for c in CATE_FEATURES] + CONTI_FEATURES\n",
    "assemblerInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8cfb9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_d13bc29328d3,\n",
       " OneHotEncoder_5d817771b9e2,\n",
       " StringIndexer_834dbdee2656,\n",
       " OneHotEncoder_2c99eff7c4a2,\n",
       " StringIndexer_722880280649,\n",
       " OneHotEncoder_7fe1de319cae,\n",
       " StringIndexer_ffb3651de9b1,\n",
       " OneHotEncoder_5f88ad0f1f8e,\n",
       " StringIndexer_424efa9aacbb,\n",
       " OneHotEncoder_a65bde17d2de,\n",
       " StringIndexer_a95c9282cb16,\n",
       " OneHotEncoder_3eac99a70a3b,\n",
       " StringIndexer_4ea144e46c03,\n",
       " OneHotEncoder_510482c280f6,\n",
       " StringIndexer_8b346fd910c8,\n",
       " OneHotEncoder_4cd872fdede8,\n",
       " StringIndexer_6a30065ccbc9,\n",
       " OneHotEncoder_fc14e6f6b8f8,\n",
       " StringIndexer_d28b980e817e,\n",
       " VectorAssembler_c3bdddd766a0]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final vector assemblers\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "318a1127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x',\n",
       " 'age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'educational-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'income']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remove.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f50864e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: string (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: float (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- capital-gain: float (nullable = true)\n",
      " |-- capital-loss: float (nullable = true)\n",
      " |-- hours-per-week: float (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data type conversion\n",
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df \n",
    "# List of continuous features\n",
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital-gain', 'educational-num', 'capital-loss', 'hours-per-week']\n",
    "# Convert the type\n",
    "df_remove = convertColumn(df_remove, CONTI_FEATURES, FloatType())\n",
    "df_remove.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "37a1ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(x='1', age=25.0, workclass='Private', fnlwgt=226802.0, education='11th', educational-num=7.0, marital-status='Never-married', occupation='Machine-op-inspct', relationship='Own-child', race='Black', gender='Male', capital-gain=0.0, capital-loss=0.0, hours-per-week=40.0, native-country='United-States', income='<=50K', workclassIndex=0.0, workclassclassVec=SparseVector(8, {0: 1.0}), educationIndex=5.0, educationclassVec=SparseVector(15, {5: 1.0}), marital-statusIndex=1.0, marital-statusclassVec=SparseVector(6, {1: 1.0}), occupationIndex=6.0, occupationclassVec=SparseVector(14, {6: 1.0}), relationshipIndex=2.0, relationshipclassVec=SparseVector(5, {2: 1.0}), raceIndex=1.0, raceclassVec=SparseVector(4, {1: 1.0}), genderIndex=0.0, genderclassVec=SparseVector(1, {0: 1.0}), native-countryIndex=0.0, native-countryclassVec=SparseVector(40, {0: 1.0}), incomeIndex=0.0, incomeclassVec=SparseVector(1, {0: 1.0}), newlabel=0.0, features=SparseVector(100, {0: 1.0, 13: 1.0, 24: 1.0, 35: 1.0, 45: 1.0, 49: 1.0, 52: 1.0, 53: 1.0, 93: 1.0, 94: 25.0, 95: 226802.0, 97: 7.0, 99: 40.0}))]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(df_remove)\n",
    "model = pipelineModel.transform(df_remove)\n",
    "model.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "62d12023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a logistic regression model\n",
    "#To make the computation faster, you convert model to a DataFrame.\n",
    "#You need to select newlabel and features from model using map.\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "input_data = model.rdd.map(lambda x: (x[\"newlabel\"], DenseVector(x[\"features\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c7de3996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  0.0|[1.0,0.0,0.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 205:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train = sqlContext.createDataFrame(input_data, [\"label\", \"features\"])\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c8d7b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(39058, 9783)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = df_train.randomSplit([.8,.2],seed=1234)\n",
    "train_data.count( ), test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a4c5125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|       29699|\n",
      "|  1.0|        9359|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.groupby('label').agg({'label': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c8658a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|        7455|\n",
      "|  1.0|        2328|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.groupby('label').agg({'label': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "96239d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/26 12:21:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/10/26 12:21:38 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid=LogisticRegression_a204be12eb61, numClasses=2, numFeatures=100"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building logistic regression\n",
    "# Import `LinearRegression`\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize `lr`\n",
    "lr = LogisticRegression(labelCol=\"label\",\n",
    "                        featuresCol=\"features\",\n",
    "                        maxIter=10,\n",
    "                        regParam=0.3)\n",
    "\n",
    "# Fit the data to the model\n",
    "linearModel = lr.fit(train_data)\n",
    "linearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "650f3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.03416816214840661,-0.03293224579727304,0.018893121473898048,-0.12810404490487237,-0.03907540103820323,0.19767975898978352,0.15470840740025515,-0.10987676402208173,-0.10732534641615692,-0.041495549249503084,0.16717957884953566,0.2605054615995495,0.0017138317111527821,-0.17127621732687565,0.0018362280631443533,-0.17277900340141406,-0.21275752582970248,0.39522140047992005,-0.19943706754962034,-0.1497797970933461,0.3864639895638318,-0.17630901438373314,-0.20772314477467202,0.29406712507551414,-0.2481983164988183,-0.12806572288472737,-0.13542560444300447,-0.12690008308238676,-0.10771812392366444,0.1706740177354208,-0.017695709882279805,0.23563510546295993,-0.08099206271364243,0.03835175594235224,-0.19715713548154026,-0.12263151780093609,-0.12852668543261234,-0.05057587255783086,-0.17622964934046156,-0.19299694715356758,0.08563316099996775,0.07256061119346253,-0.20779670494751068,0.24908853558249425,-0.14287365247963157,-0.22733400109807195,-0.16671089794767888,0.3030675333204204,0.02764930461514797,-0.09025159040844867,0.01572411128655325,-0.1208529015668864,0.1255155209542877,0.0010332517034727625,-0.19373737433088764,-0.012552322240709035,0.068622446461315,0.049665535769428865,-0.11930460378036939,0.10919569311088441,-0.1505886587648529,0.0836959054850348,-0.023802196790394182,0.13719055359336024,-0.06604560162474746,-0.1680145261271462,-0.096173119903785,0.06926501291208041,-0.19927698273809222,0.10491033669401442,-0.18083973151563928,-0.13013202884883032,-0.16080520801693535,-0.24324963438617792,-0.04526840458316957,-0.03550914487465741,0.04417923082810399,0.04310387756346221,-0.03072195997221775,-0.2273586079472607,-0.16692647596717433,-0.09567868107352746,0.18957072661551064,0.0893019115871917,-0.05085276082330008,-0.16020696877354873,0.09181853639854816,-0.2712786454825332,-0.14395058148787196,-0.20517142325527288,0.17395047358900897,-0.11719640314470212,-0.17971964593094078,-1.665591883058257,0.005324699762323274,-1.3246008186579915e-08,1.2731339833182835e-05,0.038251465687507646,0.00015796951031588804,0.0058278726597394016]\n",
      "Intercept: -1.1809231933083668\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(linearModel.coefficients))\n",
    "print(\"Intercept: \" + str(linearModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ef3e6802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "predictions = linearModel.transform(test_data)\n",
    "#see prediction schema\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0972ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 242:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|[2.97743304250235...|[0.95154415140648...|       0.0|\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|[3.17336551678498...|[0.95981957999149...|       0.0|\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|[3.07907523294043...|[0.95602131957602...|       0.0|\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|[1.82751900796753...|[0.86146590472789...|       0.0|\n",
      "|  0.0|[0.0,0.0,0.0,0.0,...|[1.51694883396958...|[0.82008874138397...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f598c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|label|count(label)|\n",
      "+-----+------------+\n",
      "|  0.0|        7455|\n",
      "|  1.0|        2328|\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model evaluations\n",
    "cm = predictions.select(\"label\", \"prediction\")\n",
    "cm.groupby('label').agg({'label' : 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "24d2f127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|prediction|count(prediction)|\n",
      "+----------+-----------------+\n",
      "|       0.0|             7771|\n",
      "|       1.0|             2012|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 262:====================================================>  (71 + 1) / 75]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cm.groupby('prediction').agg({'prediction': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6d623ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9676990698149852"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "cm.filter(cm.label == cm.prediction).count() / cm.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7789cd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995083905494825\n",
      "areaUnderROC\n"
     ]
    }
   ],
   "source": [
    "### Use ROC \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "print(evaluator.evaluate(predictions))\n",
    "print(evaluator.getMetricName())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c131b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "185640df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model: 453.401 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import *\n",
    "start_time = time()\n",
    "\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train_data)\n",
    "# likely take a fair amount of time\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train model: %.3f seconds\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1e1730c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 505:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 100.000%\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#cv model evaluator\n",
    "def accuracy_m(model): \n",
    "    predictions = model.transform(test_data)\n",
    "    cm = predictions.select(\"label\", \"prediction\")\n",
    "    acc = cm.filter(cm.label == cm.prediction).count() / cm.count()\n",
    "    print(\"Model accuracy: %.3f%%\" % (acc * 100)) \n",
    "print(accuracy_m(model = cvModel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b7fb1f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_a204be12eb61', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 2,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='family', doc='The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial'): 'auto',\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='featuresCol', doc='features column name.'): 'features',\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='labelCol', doc='label column name.'): 'label',\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='threshold', doc='Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p].'): 0.5,\n",
       " Param(parent='LogisticRegression_a204be12eb61', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel = cvModel.bestModel\n",
    "bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e10e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
